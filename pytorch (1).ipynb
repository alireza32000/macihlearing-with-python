{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install time\n",
        "# !pip install tqdm"
      ],
      "metadata": {
        "id": "pKtRfSbnQO5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGUVWac0BZcg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import torch\n",
        "%matplotlib inline\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading"
      ],
      "metadata": {
        "id": "o4uFzLVu9dG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 4\n",
        "\n",
        "# torchvision.datasets.MNIST outputs a set of PIL images\n",
        "# We transform them to tensors\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Load and transform data\n",
        "trainset = torchvision.datasets.MNIST('/tmp', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.MNIST('/tmp', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "AXEI6WX49f19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data visualization\n",
        "Let's explore the dataset, especially to determine the dimension of data."
      ],
      "metadata": {
        "id": "AjbfEjKC-aWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_batch(batch):\n",
        "    im = torchvision.utils.make_grid(batch)\n",
        "    plt.imshow(np.transpose(im.numpy(), (1, 2, 0)))"
      ],
      "metadata": {
        "id": "DX5Pv1Gq-df0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print('Labels: ', labels)\n",
        "print('Batch shape: ', images.size())\n",
        "show_batch(images)\n"
      ],
      "metadata": {
        "id": "WS6Thx4EBYW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP model\n",
        "\n",
        "\n",
        "As found above, data shape is (BACTH_SIZE, N_CHANNELS, WIDTH, HEIGHT). To feed our MLP network, we need to flatten the three last dimensions. We can do so with Tensor.view()."
      ],
      "metadata": {
        "id": "Cl_TvE4TD8oM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/docs/master/tensors.html#torch.Tensor.view\n",
        "images.view(BATCH_SIZE, -1).size()"
      ],
      "metadata": {
        "id": "2ppPsA9REFwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequentialMNIST(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SequentialMNIST, self).__init__()\n",
        "        self.linear1 = nn.Linear(28*28, 256)\n",
        "        self.linear2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_relu = F.relu(self.linear1(x.view(BATCH_SIZE, -1)))\n",
        "        y_pred = self.linear2(h_relu)\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "KjIbCHC_ELWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SequentialMNIST()\n",
        "model"
      ],
      "metadata": {
        "id": "UVAffvm6I-GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, trainloader, criterion, optimizer, n_epochs=2):\n",
        "    for t in range(n_epochs):\n",
        "        for i, data in enumerate(trainloader):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "            # TODO: why?\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels) # Compute the loss\n",
        "            loss.backward() # Compute the gradient for each variable\n",
        "            optimizer.step() # Update the weights according to the computed gradient\n",
        "\n",
        "            if not i % 2000:\n",
        "                print(t, i, loss.data[0])"
      ],
      "metadata": {
        "id": "TGJbxLVKJFnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-6)"
      ],
      "metadata": {
        "id": "nGgVjVWoVDl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, images):\n",
        "    outputs = model(Variable(images))\n",
        "    _, predicted = torch.max(outputs.data, 1)  # TODO: explain why 1\n",
        "    return predicted"
      ],
      "metadata": {
        "id": "Ys1CWzHkWKq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "show_batch(images)\n",
        "print('Prediction: ', predict(model, images))"
      ],
      "metadata": {
        "id": "YN51zqgxd8yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, testloader, n):\n",
        "    correct = 0\n",
        "    for data in testloader:\n",
        "        inputs, labels = data\n",
        "        pred= predict(model, inputs)\n",
        "        correct +=(pred == labels)\n",
        "        return 100 * correct/n\n",
        "print('Accuracy:',test(model,testloader,len(testset)))"
      ],
      "metadata": {
        "id": "VQii9GHOd_-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "vFbmKQycf5uW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNMNIST(nn.Module):\n",
        "    pass"
      ],
      "metadata": {
        "id": "oRYoaS-Wf7v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNNMNIST()\n",
        "model"
      ],
      "metadata": {
        "id": "8g39akF2gP3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FnKK3ykBjwk0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}